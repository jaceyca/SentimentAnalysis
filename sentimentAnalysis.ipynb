{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename, train=True):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string\n",
    "        (optional) train: used to determine whether this is the training or test set\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if (train):\n",
    "                # remove \\n, split on space, separate into label and weights\n",
    "                X.append(line.strip().split(' ')[1:])\n",
    "                y.append(line.strip().split(' ')[0])\n",
    "            else:\n",
    "                X.append(line.strip().split(' '))\n",
    "                \n",
    "    # convert to np, cast to int, and remove the headers\n",
    "    X = np.asarray(X[1:]).astype(int)\n",
    "    if (train):\n",
    "        y = np.asarray(y[1:]).astype(int)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x_train, y_train):\n",
    "    '''\n",
    "    Function for cross validiation. \n",
    "    \n",
    "    Inputs: \n",
    "        x_train: training data points\n",
    "        y_train: training labels\n",
    "        \n",
    "    Outputs:\n",
    "        trainX: randomized 4/5 of given data points\n",
    "        trainY: corresponding labels\n",
    "        testX: randomized 1/5 of given data points\n",
    "        testY: corresponding lables\n",
    "    '''\n",
    "    dataSplit = ShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "    for train, test in dataSplit.split(x_train, y_train):\n",
    "        return x_train[train], y_train[train], x_train[test], y_train[test] \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(clf, X, y, test):\n",
    "    '''\n",
    "    Function to train and test our classifier\n",
    "    \n",
    "    Inputs:\n",
    "        clf: classifier\n",
    "        X: data points\n",
    "        y: labels\n",
    "        test: test set\n",
    "    \n",
    "    Outputs:\n",
    "        predictions: predictions from running the clf on the test set\n",
    "    '''\n",
    "    clf.fit(X, y)\n",
    "    predictions = clf.predict(test)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data(data, filename=\"%s.txt\" % datetime.today().strftime(\"%X\").replace(\":\", \"\")):\n",
    "    '''\n",
    "    Function to save the predictions by the classifier\n",
    "    \n",
    "    Inputs: predictions, (optional) filename\n",
    "        If filename isn't specified, then it just uses the current time\n",
    "    \n",
    "    Outputs: Does not return anything\n",
    "        Writes the submisssion to a textfile that should have the same format as the sample_submission.txt\n",
    "    '''\n",
    "    \n",
    "    # Creates a new submissions folder if one doesn't exist\n",
    "    pathlib.Path('submissions').mkdir(parents=True, exist_ok=True)\n",
    "    with open(\"submissions\\\\%s\" % filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for Id, prediction in enumerate(data, 1):\n",
    "            string = str(Id) + ',' + str(prediction) + '\\n'\n",
    "            f.write(string)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridgeReg(xTrain, yTrain, xTest):\n",
    "    '''\n",
    "    Function to perform ridge regression. \n",
    "    \n",
    "    Inputs:\n",
    "        xTrain: data to train on\n",
    "        yTrain: labels of the training data\n",
    "        xTest: data to predict on\n",
    "        \n",
    "    Outputs:\n",
    "        predictions: predicted labels of the data\n",
    "    '''\n",
    "    cutoff = 0.5\n",
    "    \n",
    "    ridge = Ridge(alpha = 200)\n",
    "    ridge.fit(xTrain, yTrain)\n",
    "    predictions = ridge.predict(xTest)\n",
    "    predictions[predictions > cutoff] = 1\n",
    "    predictions[predictions < cutoff] = 0\n",
    "    ridgePred = ridgePred.astype(int)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentError(yPred, yTrue):\n",
    "    '''\n",
    "    Calculates the percent error between two given label sets\n",
    "    \n",
    "    Inputs:\n",
    "        yPred: predicted labels\n",
    "        yTrue: actual labels\n",
    "    \n",
    "    Outputs:\n",
    "        error: float of the number of mismatches divided by total length\n",
    "    '''     \n",
    "    return 1-np.sum(np.equal(yPred, yTrue))/len(yTrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradientBoost(xTrain, yTrain, xTest):\n",
    "    '''\n",
    "    Function to perform gradient boost classification. \n",
    "    \n",
    "    Inputs:\n",
    "        xTrain: data to train on\n",
    "        yTrain: labels of the training data\n",
    "        xTest: data to predict on\n",
    "        \n",
    "    Outputs:\n",
    "        predictions: predicted labels of the data\n",
    "    '''\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    \n",
    "    predictions = clf.predict(xTest)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization(X_train, X_test):\n",
    "    '''\n",
    "    Function to normalize training and test data\n",
    "\n",
    "    Inputs:\n",
    "        X_train: training set data points\n",
    "        X_test: test set data points\n",
    "\n",
    "    Outputs:\n",
    "        train_norm: normalized training set data points\n",
    "        test_norm: normalized test set data points\n",
    "    '''\n",
    "    normalizer = Normalizer().fit(X_train)\n",
    "    train_norm = normalizer.transform(X_train)\n",
    "    test_norm = normalizer.transform(X_test)\n",
    "\n",
    "    return (train_norm, test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MLP(xTrain, yTrain, xTest):\n",
    "    '''\n",
    "    Function to perform multiple linear perceptron classification. \n",
    "    \n",
    "    Inputs:\n",
    "        xTrain: data to train on\n",
    "        yTrain: labels of the training data\n",
    "        xTest: data to predict on\n",
    "        \n",
    "    Outputs:\n",
    "        predictions: predicted labels of the data\n",
    "    '''\n",
    "    mlp = MLPClassifier()\n",
    "    mlp.fit(xTrain, yTrain)\n",
    "    predictions = mlp.predict(xTest)\n",
    "    predictions = predictions.astype(int)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # load the data\n",
    "    X_train, y_train = load_data(\"training_data.txt\")\n",
    "    X_test, _ = load_data(\"test_data.txt\", False)\n",
    "\n",
    "    # normalize training and test data\n",
    "    X_train_n, X_test_n = normalization(X_train, X_test)    \n",
    "    \n",
    "    # split the data in to training and testing so we can test ourselves\n",
    "    trainX, trainY, testX, testY = split_data(X_train_n, y_train)\n",
    "\n",
    "    # testing ridge regression and the percent error function\n",
    "    ridgePred = ridgeReg(trainX, trainY, testX)\n",
    "    print(\"Ridge Regression Error:\")\n",
    "    print(percentError(ridgePred, testY))\n",
    "\n",
    "    # testing Gradient Boost\n",
    "    gradBoostRes = gradientBoost(trainX, trainY, testX)\n",
    "    print(\"Gradient Boost Error:\")\n",
    "    print(percentError(gradBoostRes, testY))\n",
    "    \n",
    "    # testing MLPClassifier\n",
    "    mlpPred = MLP(trainX, trainY, testX)\n",
    "    print(\"MLP Error:\")\n",
    "    print(percentError(mlpPred, testY))\n",
    "\n",
    "    # pick our model\n",
    "    clf = RandomForestClassifier(n_estimators=5000, criterion = 'gini')\n",
    "    # train and test our model\n",
    "    predictions = make_predictions(clf, X_train, y_train, X_test)\n",
    "\n",
    "    # save to a file\n",
    "    save_data(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTested clfs:\\nclf = SGDClassifier(loss=\"log\", penalty=\"l2\")\\nScore: 0.82240\\n\\nclf = RandomForestClassifier(n_estimators=5000, criterion = \\'gini\\')\\nScore: 0.82860\\n\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Tested clfs:\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l2\")\n",
    "Score: 0.82240\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=5000, criterion = 'gini')\n",
    "Score: 0.82860\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
